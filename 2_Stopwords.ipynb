{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "2.Stopwords.ipynb",
      "provenance": [],
      "authorship_tag": "ABX9TyOlbXywwVHDEbYpyVCi/Q7a"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "-QDetb0W_e6z"
      },
      "source": [
        "import nltk\n"
      ],
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GL4LTW7V_u0B",
        "outputId": "d0b34a90-ef9e-4e2f-bb26-b6d45fac0ee1",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "from nltk.corpus import stopwords\n",
        "from nltk.tokenize import word_tokenize\n",
        "nltk.download('stopwords')\n",
        "nltk.download('punkt')"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Package stopwords is already up-to-date!\n",
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Unzipping tokenizers/punkt.zip.\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tK9JYzgI_wf2",
        "outputId": "b490df9c-9b22-4fb7-ed30-bd3ad741b647",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "stop_words=set(stopwords.words(\"english\"))\n",
        "print(stop_words)\n"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "{'after', 'doing', 'such', 'further', 'mustn', 'same', 'ourselves', 'it', 'aren', \"hadn't\", \"wasn't\", 'y', 'hadn', 'all', 'been', 'shouldn', \"isn't\", 'whom', 'of', 'needn', 'you', 'most', 'out', 'o', 've', 'weren', 'through', 'at', 'or', 'me', 'before', 'being', 'has', 'so', 'hasn', 'did', 'm', 'd', 'above', 'off', 'isn', 'those', 'a', 'wasn', 'itself', 'because', \"couldn't\", 'why', 'll', \"won't\", 'yourself', 'myself', 'down', 'as', 'they', \"you're\", 'into', 'she', 'do', 'then', 'just', 'doesn', 'my', 'about', 'does', 'the', 'can', 'while', 'from', 'hers', \"it's\", 'her', \"you'd\", 'under', 'than', \"hasn't\", 'we', 'again', 'too', 'having', 'didn', 'there', 'herself', 'against', \"mustn't\", 'where', 're', 'should', 'few', 't', 'only', 'wouldn', \"wouldn't\", 'don', \"shouldn't\", 'that', 'to', 'is', \"aren't\", 'yourselves', 'any', 'won', 'their', 'when', 'i', 'over', 'its', 'your', \"don't\", \"you'll\", 'theirs', 'am', 'with', 'once', 'very', 'mightn', \"weren't\", 'were', 'what', 'ain', \"didn't\", 'each', 'ours', 'here', \"that'll\", 'during', 'below', 'ma', \"mightn't\", 'these', 'haven', 'own', 'our', 'be', 'have', \"should've\", 'other', \"needn't\", 'them', \"doesn't\", 'shan', 'yours', 'if', 'his', 'couldn', 'more', 'some', 'by', 'who', 'had', \"shan't\", 's', 'but', \"she's\", 'was', 'no', 'which', 'for', \"you've\", 'he', 'and', \"haven't\", 'not', 'between', 'themselves', 'are', 'on', 'this', 'an', 'up', 'nor', 'both', 'will', 'how', 'now', 'him', 'until', 'in', 'himself'}\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lGQMJsos_0Kp",
        "outputId": "849e9111-c74f-4c09-d89f-8028d195d306",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "example_sentence=\"I would like to read fiction book when there is a holiday in my University.\"\n",
        "words=word_tokenize(example_sentence)\n",
        "print(words)"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "['I', 'would', 'like', 'to', 'read', 'fiction', 'book', 'when', 'there', 'is', 'a', 'holiday', 'in', 'my', 'University', '.']\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Y4IgCs5BAHbq",
        "outputId": "2f55572d-e2f1-4447-d58b-6f9207e2a743",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "filtered_words=[]\n",
        "for w in words:\n",
        "    if w not in stop_words:\n",
        "        filtered_words.append(w)\n",
        "print(filtered_words)"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "['I', 'would', 'like', 'read', 'fiction', 'book', 'holiday', 'University', '.']\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}